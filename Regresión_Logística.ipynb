{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regresión Logística.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboltCD/aboltCD/blob/main/Regresi%C3%B3n_Log%C3%ADstica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t657Bi9wRCp6"
      },
      "source": [
        "## Regresión Logística\n",
        "\n",
        "En este notebook haremos predicciones sobre cáncer de mamas en base propiedades de sus tumores utilizando Regresiones Logísticas.\n",
        "\n",
        "Sin embargo, el plato fuerte esta vez es el uso de validación cruzada para estabilizar los resultados al disminuir los sesgos de seleccion de datos y la optimización de hiperparámetros.\n",
        "\n",
        "Comenzamos por importar las librerías necesarias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLIgjUitRRj7"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO_Ivrgcc71P"
      },
      "source": [
        "Ahora cargamos el dataset de los vinos, lo separamos en Features y Target, lo escalamos y dividimos en entrenamiento y prueba (en este caso, utilizamos un 10% de los datos como prueba):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEquSt-KdBV9"
      },
      "source": [
        "cancer = load_breast_cancer()\n",
        "\n",
        "#separamos en features y target\n",
        "\n",
        "df = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
        "df[\"cancer\"] = cancer.target\n",
        "#df[\"Cancer\"] = df[\"Cancer\"].astype('str')\n",
        "\n",
        "#Feature Matrix (todos los atributos)\n",
        "X = df.drop(\"cancer\",1)  \n",
        "\n",
        "#Target Variable\n",
        "y = df[[\"cancer\"]]   \n",
        "   \n",
        "\n",
        "#separamos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.10, random_state = 1)\n",
        "\n",
        "#escalamos solo los features X (y es una categoría, por lo que no debe ser escalada)\n",
        "scalerX = StandardScaler().fit(X_train)\n",
        "\n",
        "X_train = scalerX.transform(X_train)\n",
        "X_test = scalerX.transform(X_test)\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMf0jmFYerRQ"
      },
      "source": [
        "Ahora, buscamos los mejores parámetros para la regresión logística utilizando Grid Search Cross Validation para buscar el mejor parámetro en una \"Grilla\" de posibles candidatos (combinaciones de valores de parámetros) en donde cáda candidato será evaluado con validación cruzada.\n",
        "\n",
        "Notemos ahora, que el \"param grid\" tiene varias configuraciones. Esto se debe a que algunos solvers no soportan regularizaciones lasso, ridge, o elasticnet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5Ldr15deq5u",
        "outputId": "0e486932-4298-4677-a94f-982367e621d9"
      },
      "source": [
        "param_grid = [\n",
        "    {'penalty': ['none'], 'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], 'max_iter': [200, 500]}, \n",
        "    {'penalty': ['l1'] , 'solver': ['liblinear', 'saga'], 'C': [1000, 500, 100, 50, 20, 10, 5, 1], 'max_iter': [200, 500]},\n",
        "    {'penalty': ['elasticnet'], 'solver': ['saga'], 'C': [1000, 500, 100, 50, 20, 10, 5, 1], 'max_iter': [200, 500]},\n",
        "    {'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'], 'C': [1000, 500, 100, 50, 20, 10, 5, 1], 'max_iter': [200, 500]},\n",
        " ]\n",
        "\n",
        "reglog = GridSearchCV(estimator = LogisticRegression( multi_class = 'ovr'), param_grid = param_grid, scoring = 'accuracy', cv=10) \n",
        "\n",
        "reglog.fit(X_train, y_train.values.ravel())\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='ovr',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'max_iter': [200, 500], 'penalt...\n",
              "                          'max_iter': [200, 500], 'penalty': ['l1'],\n",
              "                          'solver': ['liblinear', 'saga']},\n",
              "                         {'C': [1000, 500, 100, 50, 20, 10, 5, 1],\n",
              "                          'max_iter': [200, 500], 'penalty': ['elasticnet'],\n",
              "                          'solver': ['saga']},\n",
              "                         {'C': [1000, 500, 100, 50, 20, 10, 5, 1],\n",
              "                          'max_iter': [200, 500], 'penalty': ['l2'],\n",
              "                          'solver': ['newton-cg', 'lbfgs', 'liblinear',\n",
              "                                     'sag']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImdfBZJNQt3K",
        "outputId": "3418ea93-3083-4f59-a226-4de533e96bc2"
      },
      "source": [
        "print(\"Mejor score (accuracy): \", reglog.best_score_)\n",
        "print(\"Mejores hiperparámetros: \", reglog.best_params_)\n",
        "print(\"Mejor modelo: \", reglog.best_estimator_)\n",
        "\n",
        "best_model = reglog.best_estimator_"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor score (accuracy):  0.9746983408748114\n",
            "Mejores hiperparámetros:  {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Mejor modelo:  LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
            "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-6WB_X0In4n"
      },
      "source": [
        "Ahora podemos obtener el mejor \"modelo\". No olvidemos reentrenarlo con los datos de entrenamiento completos. Queremos utilizar sólo los hiperparámetros de este mejor modelo. Luego imprimimos sus scores finales con respecto a los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-9BARTvVCkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82013a34-c120-4499-d2d6-4d018c94b2dc"
      },
      "source": [
        "best_model.fit(X_train,y_train.values.ravel())\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=cancer.target_names))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   malignant       1.00      1.00      1.00        23\n",
            "      benign       1.00      1.00      1.00        34\n",
            "\n",
            "    accuracy                           1.00        57\n",
            "   macro avg       1.00      1.00      1.00        57\n",
            "weighted avg       1.00      1.00      1.00        57\n",
            "\n"
          ]
        }
      ]
    }
  ]
}